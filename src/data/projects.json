[
    {
    "id": 1,
    "title": "Reinforcement Learning-based Robotic Manipulation with Koopman Generator",
    "category": "Robotics & Machine Learning",
    "description": "Advanced a reinforcement learning-based robotic object picking system using NVIDIA Isaac Sim and Proximal Policy Optimization (PPO), achieving a 30% improvement in task completion time and a 25% reduction in collision errors. Used a Koopman-based linear model to transform complex robot dynamics into a simplified linear form, achieving smoother and more stable robotic arm motions, with a 40% reduction in erratic movements.",
    "longDescription": "This project involved developing a robotic manipulation system leveraging reinforcement learning and Koopman-based linear models. The system integrates advanced simulation tools and machine learning techniques to optimize robotic arm control and object manipulation tasks.",
    "technologies": ["Isaac Sim", "Python", "PPO", "Koopman Generator", "C++", "Reinforcement Learning", "OpenCV"],
    "frameworks": ["NVIDIA Isaac Gym", "PyTorch", "Koopman Operator"],
    "image": "/src/assets/robotic-manipulation-project.jpg",
    "video": "https://youtu.be/FQf7SH3lpH0",
    "github": "https://github.com/VamsiKrishna1211/DL-CSCI-5527-Project",
    "demo": null,
    "status": "Completed",
    "featured": true,
    "highlights": [
      "30% improvement in task completion time",
      "25% reduction in collision errors",
      "Smoother and more stable robotic arm motions",
      "40% reduction in erratic movements",
      "Integration of Koopman-based linear models for dynamic simplification"
    ],
    "challenges": [
      "Complex robot dynamics transformation",
      "Real-time reinforcement learning constraints",
      "Collision avoidance in dense environments",
      "Optimizing PPO for robotic control"
    ],
    "learned": [
      "Designing reinforcement learning pipelines",
      "Implementing Koopman-based dynamic models",
      "IsaacLab integration for multiscale simulation",
      "Optimizing robotic control algorithms",
      "Simulation-to-reality transfer techniques",
      "Control strategies for robotic manipulation",
      "Reward Function Engineering"
    ]
  },
  {
    "id": 1,
    "title": "Indoor Mapping Using Semantic 3D SLAM in ROS",
    "category": "Robotics & Computer Vision",
    "description": "Developed and implemented a semantic 3D SLAM algorithm within the ROS framework for autonomous indoor navigation of TurtleBot 3 in GPS-denied environments, achieving over 95% accuracy in 3D mapping and localization. Enhanced the navigation system with dynamic obstacle avoidance and adaptive behavior modes, validated through high-fidelity simulations using Isaac Sim, demonstrating a 70% improvement in navigation efficiency in complex indoor scenarios.",
    "longDescription": "This project involved developing a comprehensive autonomous indoor navigation system using advanced computer vision and SLAM techniques. The system integrates multiple sensors and compute platforms to enable safe autonomous navigation in complex environments.",
    "technologies": ["Isaac Sim", "Python", "ROS2", "Isaac ROS", "C++", "SLAM", "OpenCV", "Stereo Vision", "Camera Calibration"],
    "frameworks": ["ORB-SLAM3", "RTAB-Map", "TurtleBot 3", "Isaac Sim"],
    "image": "/src/assets/indoor-mapping-project.jpg",
    "video": "https://youtu.be/ni7CDQVyHyE",
    "github": "https://github.com/VamsiKrishna1211/CV-CSCI-5561-Project",
    "demo": null,
    "status": "Completed",
    "featured": true,
    "highlights": [
      "Semantic 3D SLAM implementation with ROS",
      "Dynamic obstacle avoidance and adaptive behavior modes",
      "High-fidelity simulations using Isaac Sim",
      "Achieved over 95% accuracy in 3D mapping and localization",
      "70% improvement in navigation efficiency in complex indoor scenarios"
    ],
    "challenges": [
      "Autonomous navigation in GPS-denied environments",
      "Real-time processing constraints on edge hardware",
      "Sensor fusion and calibration accuracy",
      "Safety protocols for autonomous navigation"
    ],
    "learned": [
      "3D point cloud generation from stereo vision",
      "Landmark detection and tracking in SLAM",
      "ROS 2 integration for seamless sensor communication",
      "Integrating with IMU and Camera systems"
    ]
  },
  {
    "id": 1,
    "title": "Autonomous Drone 3D Mapping with Stereo SLAM",
    "category": "Robotics & Computer Vision",
    "description": "Developed an autonomous drone system utilizing custom-built stereo vision system with real-time 3D mapping and localization in GPS-denied environments.",
    "longDescription": "This project involved developing a comprehensive autonomous drone navigation system using advanced computer vision and SLAM techniques. The system integrates multiple sensors and compute platforms to enable safe autonomous flight in complex environments.",
    "technologies": ["Python", "ROS 2", "ArduPilot", "C++", "SLAM", "OpenCV", "Stereo Vision", "Camera Calibration"],
    "frameworks": ["ORB-SLAM3", "RTAB-Map", "Jetson Orin Nano", "Pixhawk"],
    "image": "/src/assets/drone-slam-project.jpg",
    "video": "https://youtu.be/H-qnpfanvtA",
    "github": "https://github.com/VamsiKrishna1211/Stereo-Vision",
    "demo": null,
    "status": "Completed",
    "featured": true,
    "highlights": [
      "Custom stereo vision system with Raspberry Pi cameras",
      "Manual camera calibration for accurate depth perception",
      "Real-time 3D mapping and localization using Visual-Inertial SLAM",
      "ROS 2 integration for seamless sensor communication",
      "Comprehensive testing in simulation before real deployment"
    ],
    "challenges": [
      "Autonomous navigation in GPS-denied environments",
      "Real-time processing constraints on edge hardware",
      "Sensor fusion and calibration accuracy",
      "Safety protocols for autonomous flight operations"
    ],
    "learned": [
      "Practical stereo camera calibration workflow",
      "Tuning visual-inertial SLAM for embedded GPUs",
      "Designing safety fallbacks for autonomous drones",
      "Team work and project management in robotics"
    ]
  },
  {
    "id": 2,
    "title": "Image-Based Visual Servoing (IBVS) for Robotic Arm Control",
    "category": "Computer Vision & Robotics",
    "description": "Engineered a robotic arm control system using real-time visual feedback for precise object manipulation and grasping tasks.",
    "longDescription": "This project implements Image-Based Visual Servoing for robotic arm control, enabling dynamic real-time adjustment based on visual feedback. The system integrates stereo vision, object detection, and control algorithms for accurate manipulation.",
    "technologies": ["Python", "ROS", "OpenCV", "PyTorch", "Open3D", "TensorRT"],
    "frameworks": ["YOLOv8", "Stereo Anything", "Raspberry Pi"],
    "image": "/src/assets/ibvs-project.jpg",
    "video": null,
    "github": "https://github.com/VamsiKrishna1211/ibvs-robotic-arm",
    "demo": null,
    "status": "Completed",
    "featured": true,
    "highlights": [
      "Custom stereo camera system with comprehensive calibration",
      "3D point cloud generation from disparity maps",
      "Real-time object detection and segmentation using YOLOv8",
      "TensorRT optimization achieving <5ms inference times",
      "Dynamic visual servoing control for precise manipulation"
    ],
    "challenges": [
      "Real-time stereo vision processing",
      "Accurate depth estimation for manipulation",
      "Visual servoing control loop stability",
      "Integration of multiple AI models in real-time pipeline"
    ],
    "learned": [
      "Latency budgeting across perception-control loop",
      "Optimizing deep models with TensorRT INT8",
      "Ensuring stability in IBVS control laws",
      "Collaboration and Team work"
    ]
  },
  {
    "id": 3,
    "title": "Custom Quadcopter Design & Development",
    "category": "Autonomous Systems",
    "description": "Designed and built a high-performance quadcopter with advanced flight capabilities and extended range for autonomous operations.",
    "longDescription": "Complete quadcopter development project from component selection to flight testing, focusing on maximizing flight time, range, and payload capacity while maintaining stable autonomous flight capabilities.",
    "technologies": ["Pixhawk", "ArduPilot", "C++", "Mission Planner"],
    "frameworks": ["PX4", "MAVLink"],
    "image": "/src/assets/quadcopter-project.jpg",
    "video": null,
    "github": "https://github.com/VamsiKrishna1211/custom-quadcopter",
    "demo": null,
    "status": "Completed",
    "featured": false,
    "highlights": [
      "Flight range of 2.8 kilometers with constant telemetry",
      "20-minute flight time with 6200mAh battery",
      "6kg payload capacity for mission equipment",
      "7+ story building altitude capability",
      "Advanced autonomous flight modes"
    ],
    "challenges": [
      "Power distribution optimization",
      "Telemetry range extension",
      "Payload integration without affecting flight dynamics",
      "Safety protocols for high-altitude operations"
    ],
    "learned": [
      "Battery and propeller trade-offs for endurance",
      "Long-range telemetry configuration",
      "MAVLink message debugging techniques"
    ]
  },
  {
    "id": 4,
    "title": "Image Super Resolution using SRGAN",
    "category": "Deep Learning & Computer Vision",
    "description": "Implemented deep learning model for upscaling 720p video content to 4K resolution using Super Resolution Generative Adversarial Networks.",
    "longDescription": "Advanced image processing project implementing SRGAN for real-time video upscaling, with significant optimizations for memory efficiency and large-scale video processing.",
    "technologies": ["Python", "PyTorch", "OpenCV", "CUDA"],
    "frameworks": ["SRGAN", "GAN"],
    "image": "/src/assets/super-resolution-project.jpg",
    "video": null,
    "github": "https://github.com/VamsiKrishna1211/image-super-resolution",
    "demo": null,
    "status": "Completed",
    "featured": false,
    "highlights": [
      "Successful 720p to 4K upscaling implementation",
      "40% reduction in GPU memory consumption",
      "Dynamic memory allocation for large video processing",
      "Efficient CPU-GPU data transfer optimization"
    ],
    "challenges": [
      "Memory optimization for large video files",
      "Real-time processing requirements",
      "Quality preservation during upscaling",
      "Hardware resource management"
    ],
    "learned": [
      "Stabilizing GAN training with perceptual loss",
      "GPU memory profiling and optimization",
      "Balancing speed vs quality in SR models"
    ]
  },
  {
    "id": 5,
    "title": "Real-Time Audio Noise Cancellation",
    "category": "Deep Learning & Signal Processing",
    "description": "Developed deep learning-based noise cancellation system using Wave-UNet architecture for real-time audio processing.",
    "longDescription": "Advanced audio processing project implementing deep learning techniques for intelligent noise cancellation, utilizing large-scale datasets and optimized training strategies.",
    "technologies": ["Python", "PyTorch", "Torchaudio", "Librosa", "STFT"],
    "frameworks": ["Wave-UNet", "One Cycle Learning"],
    "image": "/src/assets/noise-cancellation-project.jpg",
    "video": null,
    "github": "https://github.com/VamsiKrishna1211/Noise-Reduction-Deep-Learning",
    "demo": null,
    "status": "Completed",
    "featured": false,
    "highlights": [
      "Mozilla Common Voice and UrbanSound8k dataset integration",
      "Wave-UNet architecture implementation",
      "One Cycle Learning Rate optimization",
      "MSE loss of approximately 0.2 achieved"
    ],
    "challenges": [
      "Real-time audio processing constraints",
      "Large dataset handling and preprocessing",
      "Model optimization for low-latency inference",
      "Quality metrics for noise cancellation evaluation"
    ],
    "learned": [
      "Audio data augmentation strategies",
      "Optimizing STFT/iSTFT pipelines",
      "Effective learning rate scheduling"
    ]
  },
  {
    "id": 6,
    "title": "Pot-Hole Detection",
    "category": "Computer Vision & Deep Learning",
    "description": "Developed a comprehensive pothole detection system using deep learning techniques, achieving a mean Average Precision (mAP) exceeding 0.85 at 0.95 IoU. The system leverages advanced data augmentation and a ResNet50 backbone with RetinaNet architecture for accurate object detection.",
    "longDescription": "This project involved creating a robust pothole detection system using computer vision and deep learning. The system processes road imagery to automatically identify and localize potholes, contributing to automated road maintenance and safety assessment systems.",
    "technologies": ["Python", "PyTorch", "Fastai", "OpenCV", "Scikit-Learn", "Albumentations"],
    "frameworks": ["ResNet50", "RetinaNet", "PascalVOC", "COCO"],
    "image": "/src/assets/pothole-detection-project.jpg",
    "video": null,
    "github": "https://github.com/VamsiKrishna1211/Pothole-detection",
    "demo": null,
    "status": "Completed",
    "featured": false,
    "highlights": [
      "Compiled dataset with annotated potholes in PascalVOC and COCO formats",
      "Advanced data augmentation using Albumentations library",
      "ResNet50 backbone with RetinaNet-based architecture",
      "Achieved mAP exceeding 0.85 at 0.95 IoU",
      "Semi-synthetic data generation for improved training"
    ],
    "challenges": [
      "Dataset compilation and annotation quality",
      "Handling varying lighting and weather conditions",
      "Optimizing model performance for real-time detection",
      "Balancing precision and recall for safety-critical applications"
    ],
    "learned": [
      "Advanced data augmentation techniques with Albumentations",
      "Object detection model architecture design",
      "Performance evaluation metrics for detection tasks",
      "Dataset preparation and annotation workflows"
    ]
  }
]
